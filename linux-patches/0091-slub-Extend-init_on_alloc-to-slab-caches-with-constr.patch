From 0ecd8e6c92f2cfee9a33c4d78eab09f6ae4d9513 Mon Sep 17 00:00:00 2001
From: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
Date: Fri, 29 Nov 2019 16:27:14 +0100
Subject: [PATCH 091/101] slub: Extend init_on_alloc to slab caches with
 constructors

This has required some rework during the port to 5.13, due to
da844b787245 ("kasan, mm: integrate slab init_on_alloc with HW_TAGS"),
and the patch is actually quite simpler now since we do not need to
unpoison objects anymore.

Signed-off-by: Levente Polyak <levente@leventepolyak.net>
Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
[nicolas.bouchinet@ssi.gouv.fr: pre/post-alloc hooks moved from mm/slab.h to mm/slub.c (see 6011be59910fb12b7)]
Signed-off-by: Nicolas Bouchinet <nicolas.bouchinet@ssi.gouv.fr>
---
 mm/slab.h | 2 ++
 mm/slub.c | 2 ++
 2 files changed, 4 insertions(+)

diff --git a/mm/slab.h b/mm/slab.h
index 1233598694a52..c9b44f57bd8ea 100644
--- a/mm/slab.h
+++ b/mm/slab.h
@@ -623,8 +623,10 @@ static inline bool slab_want_init_on_alloc(gfp_t flags, struct kmem_cache *c)
 {
 	if (static_branch_maybe(CONFIG_INIT_ON_ALLOC_DEFAULT_ON,
 				&init_on_alloc)) {
+#ifndef CONFIG_SLUB
 		if (c->ctor)
 			return false;
+#endif
 		if (c->flags & (SLAB_TYPESAFE_BY_RCU | SLAB_POISON))
 			return flags & __GFP_ZERO;
 		return true;
diff --git a/mm/slub.c b/mm/slub.c
index afd366c3c7b02..01ccb960b5f7d 100644
--- a/mm/slub.c
+++ b/mm/slub.c
@@ -4283,6 +4283,8 @@ bool slab_post_alloc_hook(struct kmem_cache *s, struct list_lru *lru,
 		if (p[i] && init && (!kasan_init ||
 				     !kasan_has_integrated_init()))
 			memset(p[i], 0, zero_size);
+		if (p[i] && init && s->ctor)
+			s->ctor(p[i]);
 		kmemleak_alloc_recursive(p[i], s->object_size, 1,
 					 s->flags, init_flags);
 		kmsan_slab_alloc(s, p[i], init_flags);
-- 
2.51.2

